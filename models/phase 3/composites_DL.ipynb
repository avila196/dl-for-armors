{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning to find the response of a Ballistic Composite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports needed for DL and handling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading of CSV file with all pre-calculated data for composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2_h</th>\n",
       "      <th>L2_E</th>\n",
       "      <th>L4_h</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.501944</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>0.303293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501944</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>0.303293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501944</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>0.303293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501944</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>0.312042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.501944</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>0.312042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       L2_h        L2_E      L4_h  Y\n",
       "0  0.501944  18000000.0  0.303293  1\n",
       "1  0.501944  18000000.0  0.303293  1\n",
       "2  0.501944  18000000.0  0.303293  1\n",
       "3  0.501944  18000000.0  0.312042  1\n",
       "4  0.501944  18000000.0  0.312042  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composites_data = pd.read_csv(\"./data/all_data_2.csv\")\n",
    "composites_data.drop(composites_data.iloc[:, 0:12], inplace = True, axis = 1)\n",
    "composites_data.drop(composites_data.iloc[:, 6:12], inplace = True, axis = 1)\n",
    "composites_data.drop(composites_data.iloc[:, 12:-1], inplace = True, axis = 1)\n",
    "composites_data.drop([\"L2_sf_t\", \"L2_sf_c\", \"L2_rel\", \"L4_E\", \"L4_rho\", \"L4_sf_t\", \"L4_sf_c\", \"L4_rel\", \"L2_rho\"], inplace=True, axis=1)\n",
    "composites_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing of data and definition of the Model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of true labels:  0.5533707865168539\n",
      "Percentage of false labels:  0.44662921348314605\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "\n",
    "#Split data into training and testing data\n",
    "train_data = composites_data.sample(frac=0.8, random_state=123)\n",
    "test_data = composites_data.drop(train_data.index)\n",
    "\n",
    "#As all data is numeric, we can create a numpy array for all the x features (to make the operations faster) and we \n",
    "#can manually create the label y vector\n",
    "def get_numpy(data):\n",
    "    data_features = data.copy()\n",
    "    data_labels = np.array(data_features.pop('Y'))\n",
    "    data_features = np.array(data_features)\n",
    "    return data_features, data_labels\n",
    "\n",
    "comp_features_train, comp_labels_train = get_numpy(train_data)\n",
    "comp_features_test, comp_labels_test = get_numpy(test_data)\n",
    "\n",
    "#As every column doesn't have the same range and scale, it's useful to normalize the data using the Normalization layer\n",
    "#provided by the layers module\n",
    "comp_features_train = normalize(comp_features_train, axis=0)\n",
    "comp_features_test = normalize(comp_features_test, axis=0)\n",
    "\n",
    "#Number of True and False labels in the Test set\n",
    "print(\"Percentage of true labels: \",np.sum(comp_labels_test)/len(comp_labels_test))\n",
    "print(\"Percentage of false labels: \",np.sum(comp_labels_test == 0)/len(comp_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 42,306\n",
      "Trainable params: 42,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## NN MODEL\n",
    "#Model -> We will use a network with 1 hidden layer with 64 neurons on it. The final activation function will be a sigmoid\n",
    "#function (to binary classify the composites), we will use the Adam optimizer algorithm and we will use a Mean Squared Error\n",
    "#loss function. We keep track of the accuracy during the training process\n",
    "composites_model = tf.keras.Sequential([\n",
    "    #layers.LayerNormalization(),\n",
    "    layers.Dense(256, input_shape=(comp_features_train.shape[1],), activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "opt = Adam(learning_rate=0.003)\n",
    "composites_model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                           optimizer = opt, metrics=[\"accuracy\"])\n",
    "composites_model.summary()\n",
    "\n",
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95):\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1426 samples, validate on 356 samples\n",
      "Epoch 1/20\n",
      "1426/1426 [==============================] - 1s 451us/sample - loss: 0.5917 - accuracy: 0.7069 - val_loss: 0.3108 - val_accuracy: 0.8792\n",
      "Epoch 2/20\n",
      "1426/1426 [==============================] - 0s 109us/sample - loss: 0.3191 - accuracy: 0.8857 - val_loss: 0.3204 - val_accuracy: 0.8624\n",
      "Epoch 3/20\n",
      "1426/1426 [==============================] - 0s 118us/sample - loss: 0.2730 - accuracy: 0.8885 - val_loss: 0.1830 - val_accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "1426/1426 [==============================] - 0s 112us/sample - loss: 0.2833 - accuracy: 0.8850 - val_loss: 0.2290 - val_accuracy: 0.8792\n",
      "Epoch 5/20\n",
      "1426/1426 [==============================] - 0s 112us/sample - loss: 0.2469 - accuracy: 0.8955 - val_loss: 0.2946 - val_accuracy: 0.9045\n",
      "Epoch 6/20\n",
      "1426/1426 [==============================] - 0s 110us/sample - loss: 0.2239 - accuracy: 0.8962 - val_loss: 0.2290 - val_accuracy: 0.9326\n",
      "Epoch 7/20\n",
      "1426/1426 [==============================] - 0s 111us/sample - loss: 0.2451 - accuracy: 0.8976 - val_loss: 0.1665 - val_accuracy: 0.9326\n",
      "Epoch 8/20\n",
      "1426/1426 [==============================] - 0s 112us/sample - loss: 0.2609 - accuracy: 0.8892 - val_loss: 0.1510 - val_accuracy: 0.9354\n",
      "Epoch 9/20\n",
      "1426/1426 [==============================] - 0s 117us/sample - loss: 0.2271 - accuracy: 0.8948 - val_loss: 0.2478 - val_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "1426/1426 [==============================] - 0s 122us/sample - loss: 0.2397 - accuracy: 0.8955 - val_loss: 0.2143 - val_accuracy: 0.9326\n",
      "Epoch 11/20\n",
      "1426/1426 [==============================] - 0s 115us/sample - loss: 0.2039 - accuracy: 0.8955 - val_loss: 0.2744 - val_accuracy: 0.9270\n",
      "Epoch 12/20\n",
      "1426/1426 [==============================] - 0s 118us/sample - loss: 0.2203 - accuracy: 0.8983 - val_loss: 0.2679 - val_accuracy: 0.9270\n",
      "Epoch 13/20\n",
      "1426/1426 [==============================] - 0s 110us/sample - loss: 0.1953 - accuracy: 0.9067 - val_loss: 0.1575 - val_accuracy: 0.9326\n",
      "Epoch 14/20\n",
      "1426/1426 [==============================] - 0s 116us/sample - loss: 0.2086 - accuracy: 0.9018 - val_loss: 0.3196 - val_accuracy: 0.9073\n",
      "Epoch 15/20\n",
      "1426/1426 [==============================] - 0s 121us/sample - loss: 0.1957 - accuracy: 0.9088 - val_loss: 0.2065 - val_accuracy: 0.9326\n",
      "Epoch 16/20\n",
      "1426/1426 [==============================] - 0s 111us/sample - loss: 0.1965 - accuracy: 0.9109 - val_loss: 0.1777 - val_accuracy: 0.9326\n",
      "Epoch 17/20\n",
      "1426/1426 [==============================] - 0s 117us/sample - loss: 0.1983 - accuracy: 0.9060 - val_loss: 0.2032 - val_accuracy: 0.9326\n",
      "Epoch 18/20\n",
      "1426/1426 [==============================] - 0s 113us/sample - loss: 0.1952 - accuracy: 0.9067 - val_loss: 0.3322 - val_accuracy: 0.8989\n",
      "Epoch 19/20\n",
      "1426/1426 [==============================] - 0s 113us/sample - loss: 0.1918 - accuracy: 0.9067 - val_loss: 0.3239 - val_accuracy: 0.9073\n",
      "Epoch 20/20\n",
      "1426/1426 [==============================] - 0s 118us/sample - loss: 0.1944 - accuracy: 0.9081 - val_loss: 0.2037 - val_accuracy: 0.9326\n"
     ]
    }
   ],
   "source": [
    "#For training, 20 epochs will be used and callback is used to stop training when a given accuracy is reached (99.9%)\n",
    "callbacks = myCallback()\n",
    "history = composites_model.fit(comp_features_train, comp_labels_train, epochs=20, batch_size=32, \n",
    "                     callbacks=[callbacks], validation_data=(comp_features_test, comp_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.004 0.996]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.003 0.997]\n",
      " [0.002 0.998]\n",
      " [0.002 0.998]\n",
      " [0.014 0.986]\n",
      " [0.011 0.989]\n",
      " [0.011 0.989]\n",
      " [0.011 0.989]\n",
      " [0.01  0.99 ]\n",
      " [0.017 0.983]\n",
      " [0.015 0.985]\n",
      " [0.014 0.986]\n",
      " [0.014 0.986]\n",
      " [0.013 0.987]\n",
      " [0.011 0.989]\n",
      " [0.01  0.99 ]\n",
      " [0.009 0.991]\n",
      " [0.009 0.991]\n",
      " [0.009 0.991]\n",
      " [0.013 0.987]\n",
      " [0.011 0.989]\n",
      " [0.01  0.99 ]\n",
      " [0.008 0.992]\n",
      " [0.013 0.987]\n",
      " [0.011 0.989]\n",
      " [0.011 0.989]\n",
      " [0.01  0.99 ]\n",
      " [0.01  0.99 ]\n",
      " [0.008 0.992]\n",
      " [0.008 0.992]\n",
      " [0.007 0.993]\n",
      " [0.011 0.989]\n",
      " [0.011 0.989]\n",
      " [0.01  0.99 ]\n",
      " [0.01  0.99 ]\n",
      " [0.009 0.991]\n",
      " [0.009 0.991]\n",
      " [0.007 0.993]\n",
      " [0.007 0.993]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.011 0.989]\n",
      " [0.01  0.99 ]\n",
      " [0.009 0.991]\n",
      " [0.009 0.991]\n",
      " [0.008 0.992]\n",
      " [0.008 0.992]\n",
      " [0.007 0.993]\n",
      " [0.007 0.993]\n",
      " [0.007 0.993]\n",
      " [0.007 0.993]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.01  0.99 ]\n",
      " [0.01  0.99 ]\n",
      " [0.009 0.991]\n",
      " [0.008 0.992]\n",
      " [0.007 0.993]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.009 0.991]\n",
      " [0.007 0.993]\n",
      " [0.007 0.993]\n",
      " [0.007 0.993]\n",
      " [0.006 0.994]\n",
      " [0.005 0.995]\n",
      " [0.005 0.995]\n",
      " [0.008 0.992]\n",
      " [0.007 0.993]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.005 0.995]\n",
      " [0.005 0.995]\n",
      " [0.005 0.995]\n",
      " [0.005 0.995]\n",
      " [0.005 0.995]\n",
      " [0.366 0.634]\n",
      " [0.327 0.673]\n",
      " [0.31  0.69 ]\n",
      " [0.29  0.71 ]\n",
      " [0.274 0.726]\n",
      " [0.26  0.74 ]\n",
      " [0.228 0.772]\n",
      " [0.211 0.789]\n",
      " [0.336 0.664]\n",
      " [0.298 0.702]\n",
      " [0.298 0.702]\n",
      " [0.283 0.717]\n",
      " [0.283 0.717]\n",
      " [0.263 0.737]\n",
      " [0.218 0.782]\n",
      " [0.178 0.822]\n",
      " [0.307 0.693]\n",
      " [0.291 0.709]\n",
      " [0.238 0.762]\n",
      " [0.184 0.816]\n",
      " [0.279 0.721]\n",
      " [0.165 0.835]\n",
      " [0.152 0.848]\n",
      " [0.239 0.761]\n",
      " [0.171 0.829]\n",
      " [0.148 0.852]\n",
      " [0.148 0.852]\n",
      " [0.148 0.852]\n",
      " [0.136 0.864]\n",
      " [0.127 0.873]\n",
      " [0.216 0.784]\n",
      " [0.216 0.784]\n",
      " [0.2   0.8  ]\n",
      " [0.188 0.812]\n",
      " [0.14  0.86 ]\n",
      " [0.113 0.887]\n",
      " [0.113 0.887]\n",
      " [0.194 0.806]\n",
      " [0.155 0.845]\n",
      " [0.125 0.875]\n",
      " [0.117 0.883]\n",
      " [0.107 0.893]\n",
      " [0.185 0.815]\n",
      " [0.174 0.826]\n",
      " [0.151 0.849]\n",
      " [0.138 0.862]\n",
      " [0.121 0.879]\n",
      " [0.111 0.889]\n",
      " [0.089 0.911]\n",
      " [0.156 0.844]\n",
      " [0.134 0.866]\n",
      " [0.099 0.901]\n",
      " [0.092 0.908]\n",
      " [0.084 0.916]\n",
      " [0.084 0.916]\n",
      " [0.079 0.921]\n",
      " [0.99  0.01 ]\n",
      " [0.989 0.011]\n",
      " [0.989 0.011]\n",
      " [0.989 0.011]\n",
      " [0.984 0.016]\n",
      " [0.99  0.01 ]\n",
      " [0.99  0.01 ]\n",
      " [0.988 0.012]\n",
      " [0.984 0.016]\n",
      " [0.983 0.017]\n",
      " [0.98  0.02 ]\n",
      " [0.977 0.023]\n",
      " [0.988 0.012]\n",
      " [0.981 0.019]\n",
      " [0.979 0.021]\n",
      " [0.979 0.021]\n",
      " [0.977 0.023]\n",
      " [0.987 0.013]\n",
      " [0.984 0.016]\n",
      " [0.984 0.016]\n",
      " [0.983 0.017]\n",
      " [0.981 0.019]\n",
      " [0.98  0.02 ]\n",
      " [0.976 0.024]\n",
      " [0.974 0.026]\n",
      " [0.981 0.019]\n",
      " [0.979 0.021]\n",
      " [0.977 0.023]\n",
      " [0.975 0.025]\n",
      " [0.975 0.025]\n",
      " [0.965 0.035]\n",
      " [0.98  0.02 ]\n",
      " [0.976 0.024]\n",
      " [0.967 0.033]\n",
      " [0.98  0.02 ]\n",
      " [0.98  0.02 ]\n",
      " [0.979 0.021]\n",
      " [0.979 0.021]\n",
      " [0.975 0.025]\n",
      " [0.97  0.03 ]\n",
      " [0.968 0.032]\n",
      " [0.965 0.035]\n",
      " [0.965 0.035]\n",
      " [0.965 0.035]\n",
      " [0.978 0.022]\n",
      " [0.972 0.028]\n",
      " [0.972 0.028]\n",
      " [0.969 0.031]\n",
      " [0.957 0.043]\n",
      " [0.953 0.047]\n",
      " [0.95  0.05 ]\n",
      " [0.95  0.05 ]\n",
      " [0.972 0.028]\n",
      " [0.972 0.028]\n",
      " [0.967 0.033]\n",
      " [0.964 0.036]\n",
      " [0.954 0.046]\n",
      " [0.954 0.046]\n",
      " [0.946 0.054]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]\n",
      " [1.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "y = composites_model.predict(comp_features_test)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot history of model!\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
